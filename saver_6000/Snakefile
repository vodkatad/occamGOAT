models=['GAT', 'transformer_3t_2l', 'transfomer_2t_2l']

parameters_transformer = {
    'batch_sizes': [32,64],
    'learning_rates': [0.000005, 0.00001, 0.00005, 0.0001],
    'hidden_layers': [64],
    'dropout':  [0.4, 0.5, 0.6]
}

parameters_GAT = {
    'batch_sizes': [16,32,64],
    'learning_rates': [0.000005, 0.00001, 0.00005, 0.0001],
    'hidden_layers': [32,64,128]
}

parameters_sage = {
    'learning_rates': [0.01,0.005,0.001,0.0005,0.00001],
    'hidden_layers': [64, 128],
    'dropout': [0.6,0.5,0.4],
    'num_layers': [2,3,4]  # we have the two 
}

rule all:
    input: expand("data/{model}_b{batch}-l{lr}-h{hl}-d{dr}.done", model='transformer_2t_2l', batch=parameters_transformer['batch_sizes'], lr=parameters_transformer['learning_rates'], hl=parameters_transformer['hidden_layers'], dr=parameters_transformer['dropout']), expand("data/{model}_b{batch}-l{lr}-h{hl}-d{dr}.done", model='transformer_3t_2l', batch=parameters_transformer['batch_sizes'], lr=parameters_transformer['learning_rates'], hl=parameters_transformer['hidden_layers'], dr=parameters_transformer['dropout'])

rule call_model:
    output: "data/{model}_b{batch}-l{lr}-h{hl}-d{dr}.done"
    log: log="data/{model}_b{batch}-l{lr}-h{hl}-d{dr}.log"
    benchmark: "bench/{model}_b{batch}-l{lr}-h{hl}-d{dr}.time"
    shell: 
        """
            python main.py -r data -s samplesheet.csv -p filtered_annotated -e data/general_edge_list.csv -m {wildcards.model} -b {wildcards.batch} -l {wildcards.lr} -i {wildcards.hl} -d {wildcards.dr} > {log.log}
            touch {output}
        """
        
rule all_graphsage_128:
    input: expand("data/{model}_b{batch}-l{lr}-h{hl}-d{dr}-n{nl}.done", model='GraphSage_128', batch=128, lr=parameters_sage['learning_rates'], hl=parameters_sage['hidden_layers'], dr=parameters_sage['dropout'], nl=parameters_sage['num_layers'])
    
rule all_graphsage_512:
    input: expand("data/{model}_b{batch}-l{lr}-h{hl}-d{dr}-n{nl}.done", model='GraphSage_512', batch=512, lr=parameters_sage['learning_rates'], hl=parameters_sage['hidden_layers'], dr=parameters_sage['dropout'], nl=parameters_sage['num_layers'])
    
ruleorder: call_sage > call_model

rule call_sage:
    output: "data/{model}_b{batch}-l{lr}-h{hl}-d{dr}-n{nl}.done"
    log: log="data/{model}_b{batch}-l{lr}-h{hl}-d{dr}-n{nl}.log"
    benchmark: "bench/{model}_b{batch}-l{lr}-h{hl}-d{dr}-n{nl}.time"
    shell: 
        """
            python main.py -r data -s samplesheet.csv -p filtered_annotated -e data/general_edge_list.csv -m {wildcards.model} -b {wildcards.batch} -l {wildcards.lr} -i {wildcards.hl} -d {wildcards.dr} -n {wildcards.nl} > {log.log}
            touch {output}
        """

## inverted sample sheet for best architectures
#[egrassi@occam saver_6000]>grep "Test Loss" data/*log | tr -d " " |  tr ":" "\t" | sort -k4,4n | tail -n 50 | cut -f 1 | sed 's/\.log/.done/1' | sed 's/data/data_sedie/1'| tr "\n" "," | sed 's/,/","/g' 

rule all_inv:
    input: ["data_sedie/GraphSage_128_b128-l0.005-h64-d0.5-n2.done","data_sedie/GraphSage_512_b512-l0.005-h64-d0.5-n4.done","data_sedie/GraphSage_128_b128-l0.0005-h128-d0.5-n2.done","data_sedie/GraphSage_128_b128-l0.0005-h64-d0.6-n4.done","data_sedie/GraphSage_128_b128-l0.001-h128-d0.4-n4.done","data_sedie/GraphSage_128_b128-l0.001-h64-d0.5-n4.done","data_sedie/GraphSage_512_b512-l0.0005-h128-d0.6-n2.done","data_sedie/GraphSage_512_b512-l0.001-h64-d0.4-n2.done","data_sedie/GraphSage_512_b512-l0.001-h64-d0.6-n2.done","data_sedie/GraphSage_512_b512-l0.01-h64-d0.5-n4.done","data_sedie/GraphSage_512_b512-l1e-05-h64-d0.6-n4.done","data_sedie/GraphSage_128_b128-l0.01-h64-d0.4-n3.done","data_sedie/GraphSage_512_b512-l0.005-h64-d0.5-n2.done","data_sedie/GraphSage_128_b128-l0.001-h128-d0.5-n4.done","data_sedie/GraphSage_128_b128-l0.005-h128-d0.4-n4.done","data_sedie/GraphSage_128_b128-l0.01-h128-d0.6-n4.done","data_sedie/GraphSage_512_b512-l0.01-h64-d0.4-n3.done","data_sedie/GraphSage_128_b128-l0.01-h128-d0.5-n3.done","data_sedie/GraphSage_128_b128-l0.005-h64-d0.6-n4.done","data_sedie/GraphSage_128_b128-l0.0005-h128-d0.5-n4.done","data_sedie/GraphSage_512_b512-l0.001-h64-d0.4-n4.done","data_sedie/GraphSage_512_b512-l0.0005-h64-d0.6-n4.done","data_sedie/GraphSage_512_b512-l0.001-h128-d0.4-n2.done","data_sedie/GraphSage_128_b128-l1e-05-h64-d0.6-n2.done","data_sedie/GraphSage_128_b128-l0.01-h64-d0.4-n2.done","data_sedie/GraphSage_512_b512-l1e-05-h128-d0.4-n2.done","data_sedie/GraphSage_512_b512-l0.001-h64-d0.6-n3.done","data_sedie/GraphSage_512_b512-l0.01-h64-d0.4-n2.done","data_sedie/GraphSage_128_b128-l0.01-h64-d0.6-n4.done","data_sedie/GraphSage_512_b512-l0.005-h64-d0.6-n4.done","data_sedie/GraphSage_128_b128-l1e-05-h64-d0.4-n4.done","data_sedie/GraphSage_512_b512-l0.01-h64-d0.4-n4.done","data_sedie/GraphSage_512_b512-l0.0005-h64-d0.5-n4.done","data_sedie/GraphSage_128_b128-l0.01-h64-d0.4-n4.done","data_sedie/GraphSage_128_b128-l0.005-h64-d0.5-n4.done","data_sedie/GraphSage_512_b512-l0.001-h64-d0.6-n4.done","data_sedie/GraphSage_128_b128-l1e-05-h128-d0.4-n2.done","data_sedie/GraphSage_512_b512-l1e-05-h64-d0.4-n4.done","data_sedie/GraphSage_512_b512-l0.0005-h128-d0.5-n2.done","data_sedie/GraphSage_128_b128-l0.005-h64-d0.5-n3.done","data_sedie/GraphSage_512_b512-l1e-05-h128-d0.6-n2.done","data_sedie/GraphSage_128_b128-l1e-05-h128-d0.6-n2.done","data_sedie/GraphSage_512_b512-l0.001-h128-d0.4-n3.done","data_sedie/GraphSage_128_b128-l1e-05-h128-d0.6-n4.done","data_sedie/GraphSage_128_b128-l0.001-h64-d0.6-n4.done","data_sedie/GraphSage_512_b512-l1e-05-h64-d0.6-n2.done","data_sedie/GraphSage_128_b128-l1e-05-h128-d0.4-n3.done","data_sedie/GraphSage_512_b512-l1e-05-h64-d0.6-n3.done","data_sedie/GraphSage_512_b512-l0.005-h64-d0.5-n3.done","data_sedie/GraphSage_128_b128-l0.0005-h128-d0.6-n4.done"] 

rule call_sage_inv:
    output: "data_sedie/{model}_b{batch}-l{lr}-h{hl}-d{dr}-n{nl}.done"
    log: log="data_sedie/{model}_b{batch}-l{lr}-h{hl}-d{dr}-n{nl}.log"
    benchmark: "bench_sedie/{model}_b{batch}-l{lr}-h{hl}-d{dr}-n{nl}.time"
    shell: 
        """
            python main.py -r data -s samplesheet_sedie.csv -p filtered_annotated -e data/general_edge_list.csv -m {wildcards.model} -b {wildcards.batch} -l {wildcards.lr} -i {wildcards.hl} -d {wildcards.dr} -n {wildcards.nl} > {log.log}
            touch {output}
        """

## TopK
parameters_sagek = {
    'learning_rates': [0.01,0.005,0.001,0.0005,0.00001],
    'hidden_layers': [64, 128],
    'dropout': [0.6,0.5,0.4],
    'num_layers': [2,3,4],  # we have the two 
    'topk': [0.6, 0.7, 0.8, 0.9]
}

rule allk:
    input: expand("testk/GraphSage_topk-b{batch}-l{lr}-h{hl}-d{dr}-n{nl}-k{topk}.done", batch=128, lr=parameters_sagek['learning_rates'], hl=parameters_sagek['hidden_layers'], dr=parameters_sagek['dropout'], nl=parameters_sagek['num_layers'], topk=parameters_sagek['topk'])

rule call_sage_topk:
    output: "testk/GraphSage_topk-b{batch}-l{lr}-h{hl}-d{dr}-n{nl}-k{topk}.done"
    log: log="testk/GraphSage_topk-b{batch}-l{lr}-h{hl}-d{dr}-n{nl}-k{topk}.log"
    benchmark: "bench_topk/GraphSage_topk-b{batch}-l{lr}-h{hl}-d{dr}-n{nl}-k{topk}.time"
    shell: 
        """
            python main_topk.py -r testk -s samplesheet.csv -p filtered_annotated -e data/general_edge_list.csv -m GraphSage_topk -b {wildcards.batch} -l {wildcards.lr} -i {wildcards.hl} -d {wildcards.dr} -n {wildcards.nl} -k {wildcards.topk} > {log.log}
            touch {output}
        """

